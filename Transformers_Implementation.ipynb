{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "n5uAItQusNEb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Encoding Language into Word Embeddings and Positional Encodings"
      ],
      "metadata": {
        "id": "nbS5vbEsyuvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This is an awesome jupyter notebook for begginers\"\n",
        "# A simple word to id mapping\n",
        "word2id = {word: i for i,word in enumerate(set(sentence.split()))}"
      ],
      "metadata": {
        "id": "ZSWq1nkVsk92"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHN1aVvnzNqb",
        "outputId": "66fab173-ebb1-4ce1-c5ee-68fdc69c40db"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'an': 0,\n",
              " 'for': 1,\n",
              " 'begginers': 2,\n",
              " 'notebook': 3,\n",
              " 'jupyter': 4,\n",
              " 'awesome': 5,\n",
              " 'This': 6,\n",
              " 'is': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting text to indices\n",
        "input_ids = torch.tensor([word2id[word] for word in sentence.split()])"
      ],
      "metadata": {
        "id": "_vQyk60OzOmK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMm3pUSf1Jug",
        "outputId": "10190495-a1a2-4799-f05b-1c7966cf71a2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 7, 0, 5, 4, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_embeddings(input_ids, embedding_size):\n",
        "  embedding_layer = nn.Embedding(input_ids.max()+1, embedding_size)\n",
        "  return embedding_layer(input_ids)\n",
        "\n",
        "embedding_size = 16\n",
        "word_embeddings = get_word_embeddings(input_ids, embedding_size)"
      ],
      "metadata": {
        "id": "LQqeljRB1Kfn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXBmcLLl1thm",
        "outputId": "877cde35-b870-448f-c540-83628123a23f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.7732e-01, -1.7875e+00,  3.2842e-01, -6.9614e-01, -4.8572e-01,\n",
              "          7.3380e-01, -7.1722e-01, -3.5299e-01,  3.4001e-01, -1.2634e-02,\n",
              "          9.9393e-01, -1.0153e+00, -1.7011e-01,  1.2828e+00, -6.2329e-02,\n",
              "          1.0504e+00],\n",
              "        [ 1.0578e+00,  1.4519e+00,  2.3196e+00, -6.9701e-01,  2.9474e-01,\n",
              "         -9.4667e-01,  1.8872e+00,  1.7656e-01, -1.2878e+00,  1.5229e+00,\n",
              "         -3.4224e-01, -2.1905e-01, -1.4975e+00, -4.7021e-01,  6.1198e-01,\n",
              "         -1.2806e-01],\n",
              "        [-8.2940e-01, -8.6052e-01,  1.4146e-01, -9.0389e-01,  6.4459e-01,\n",
              "         -1.2700e+00, -1.3968e+00, -1.2418e+00, -6.1304e-01, -1.2733e+00,\n",
              "         -3.2748e-01, -1.5087e+00,  7.6330e-01,  1.1904e+00, -1.0604e+00,\n",
              "          2.0609e-01],\n",
              "        [-8.2693e-01, -1.9949e+00, -5.3386e-01, -1.1536e+00,  6.0652e-01,\n",
              "         -7.5105e-01,  8.8081e-01,  8.7497e-01,  9.5998e-01,  7.2323e-02,\n",
              "         -2.5221e-01,  1.4166e-03,  2.5746e-01,  1.1236e+00,  1.0645e+00,\n",
              "          8.3294e-01],\n",
              "        [ 5.0048e-01,  1.8966e-01,  1.3989e+00, -2.0331e-01, -1.3320e+00,\n",
              "         -1.3013e+00, -7.2362e-01, -1.6461e+00, -5.1612e-01, -1.6862e+00,\n",
              "          4.7759e-01, -8.0449e-01, -5.4562e-02,  2.2847e-01,  1.0402e+00,\n",
              "         -2.3417e+00],\n",
              "        [ 2.3780e+00,  1.8931e-01, -1.6088e+00,  9.2828e-01,  9.7440e-01,\n",
              "         -3.8455e-01, -9.9387e-01, -4.4448e-01,  1.0588e+00, -5.0321e-01,\n",
              "         -3.2767e-01,  8.8571e-01,  3.2403e-02,  7.5352e-01,  6.4686e-01,\n",
              "          1.2069e+00],\n",
              "        [ 5.6706e-01, -4.4442e-01,  8.4334e-01, -4.3506e-01, -6.1607e-01,\n",
              "          1.3443e+00,  2.8439e-01, -1.4204e+00,  3.0571e-01, -2.0449e+00,\n",
              "          1.4657e-02, -2.5837e+00, -9.2067e-02, -6.5033e-01, -4.6751e-02,\n",
              "         -1.5876e+00],\n",
              "        [-4.7932e-01, -2.5018e+00, -6.5617e-01, -1.3563e+00, -4.3133e-01,\n",
              "          5.8582e-01, -6.3102e-01, -6.2996e-01,  4.9847e-01, -1.6008e+00,\n",
              "          1.2516e+00, -3.0063e-01,  1.8120e+00,  1.0169e+00,  3.1359e-01,\n",
              "         -1.0127e+00]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to generate positional encodings\n",
        "def get_positional_encodings(max_seq_len, d_model):\n",
        "  position = np.arange(max_seq_len)[:, np.newaxis]\n",
        "  div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0)/ d_model))\n",
        "  positional_encoding = np.zeros((max_seq_len, d_model))\n",
        "  positional_encoding[:, 0::2] = np.sin(position * div_term)\n",
        "  positional_encoding[:, 1::2] = np.cos(position * div_term)\n",
        "  return torch.tensor(positional_encoding, dtype=torch.float)"
      ],
      "metadata": {
        "id": "3OpZGyCn1uCb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = len(sentence.split())\n",
        "d_model = embedding_size # same size of the word embeddings\n",
        "positional_encodings = get_positional_encodings(max_seq_len, d_model)\n",
        "\n",
        "#Adding word embeddings and positional encodings\n",
        "final_embeddings = word_embeddings + positional_encodings\n"
      ],
      "metadata": {
        "id": "nkzsvDP64Py2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_embeddings.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "God3G0555N2d",
        "outputId": "9bb30ddb-9d18-4096-c075-2acdcf168daf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Decoder from Scratch"
      ],
      "metadata": {
        "id": "o0hEkYdr9Bmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, ff_hidden_dim, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    # d_model : The dimension of the inputer vector, our case it is  dimension of of word embeddings\n",
        "    # num_heads : the number of heads in the multihead attention mechanism\n",
        "    # ff_hidden_dim: the dimension of the feed forward hidden layer\n",
        "\n",
        "    self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.linear1 = nn.Linear(d_model, ff_hidden_dim)\n",
        "    self.linear2 = nn.Linear(ff_hidden_dim, d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "# x: input tensor\n",
        "# tgt_mask: masks to prevent attention to certain positions\n",
        "  def forward(self, x, tgt_mask):\n",
        "    attn_output, _ = self.self_attention(x, x, x, attn_mask=tgt_mask)\n",
        "    x = x + self.dropout1(attn_output)\n",
        "    x = self.norm1(x)\n",
        "    ff_output = self.linear2(F.relu(self.linear1(x)))\n",
        "    x = x + self.dropout2(ff_output)\n",
        "    x = self.norm2(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "K5WhRxx-9Ecb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "    pe[: ,0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0).transpose(0,1)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.pe[:x.size(0), :]\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "zKNAMqWMIa-l"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, num_heads, ff_hidden_dim, dropout):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "    self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "    self.transformer_block = DecoderBlock(d_model, num_heads, ff_hidden_dim, dropout)\n",
        "    self.linear = nn.Linear(d_model, vocab_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.pos_encoder(x)\n",
        "    tgt_mask = generate_square_subsequent_mask(x.size(0))\n",
        "    x = self.transformer_block(x, tgt_mask)\n",
        "    output = self.linear(x)\n",
        "    output = self.softmax(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "MnKdgx3kJoB1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "  \"\"\"Generate a mask to prevent attention to future positions\"\"\"\n",
        "  mask = (torch.triu(torch.ones(sz, sz))==1).transpose(0,1)\n",
        "  mask = mask.float().masked_fill(mask ==0, float('-inf')).masked_fill(mask ==1, float(0.0))\n",
        "  return mask"
      ],
      "metadata": {
        "id": "8JGYwdbKK7ev"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "d_model = 512\n",
        "num_heads = 1\n",
        "ff_hidden_dim = 2*d_model\n",
        "dropout = 0.1\n",
        "num_layers = 10\n",
        "context_length = 50\n",
        "batch_size = 1\n",
        "\n",
        "model = TransformerDecoder(vocab_size, d_model, num_heads, ff_hidden_dim, dropout)"
      ],
      "metadata": {
        "id": "L60QqY-RLYwT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAm4_tkFL0wI",
        "outputId": "cd3a5de9-df26-4876-edc2-adfc48224048"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerDecoder(\n",
              "  (embedding): Embedding(1000, 512)\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer_block): DecoderBlock(\n",
              "    (self_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout1): Dropout(p=0.1, inplace=False)\n",
              "    (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor representing a batch of 1 sequence of length 10\n",
        "input_tensor = torch.randint(0, vocab_size, (context_length, batch_size))\n",
        "\n",
        "# Forward pass through the model\n",
        "\n",
        "output = model.forward(input_tensor)\n"
      ],
      "metadata": {
        "id": "CPXPVVV7L6Kw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VBjBGcSMcGE",
        "outputId": "0cb3dbf2-4aa4-4815-ce80-e912dc60dcee"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_indices = output.argmax(dim=-1)\n",
        "\n",
        "print(predicted_indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UvIUNx8MeVQ",
        "outputId": "70c3e6bd-daca-4702-a271-b9847a3b00bd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgkIBJWPMn10",
        "outputId": "15464149-319f-4f2c-b785-77a9c2eaa597"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 3,127,784 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Multi-layer Decoder"
      ],
      "metadata": {
        "id": "PYlQ03b6NmRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLayerTransformer(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, num_heads, ff_hidden_dim, dropout, num_layers):\n",
        "    super(MultiLayerTransformer, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "    self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "    self.transformer_blocks = nn.ModuleList([\n",
        "        DecoderBlock(d_model,num_heads, ff_hidden_dim, dropout)\n",
        "        for _ in range(num_layers)\n",
        "    ])\n",
        "    self.linear = nn.Linear(d_model, vocab_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.pos_encoder(x)\n",
        "    for transformer_block in self.transformer_blocks:\n",
        "      tgt_mask = generate_square_subsequent_mask(x.size(0))\n",
        "      x = transformer_block(x, tgt_mask)\n",
        "    output = self.linear(x)\n",
        "    output = self.softmax(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ORqnSWXFNRUs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "d_model = 2048\n",
        "num_heads = 1\n",
        "ff_hidden_dim = 4*d_model\n",
        "dropout = 0.1\n",
        "num_layers = 10\n",
        "context_length = 100\n",
        "batch_size = 1\n",
        "\n",
        "input_tensor = torch.randint(0, vocab_size, (context_length, batch_size))\n",
        "\n",
        "model = MultiLayerTransformer(vocab_size, d_model, num_heads, ff_hidden_dim, dropout, num_layers)"
      ],
      "metadata": {
        "id": "PXt9dOTtQCCw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS58gq-RQhQ8",
        "outputId": "49ac3af6-e6a9-4668-8bd8-2ba2647ff6b0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 507,679,720 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_tensor)\n",
        "\n",
        "distribution = torch.exp(output[0, 0, :])\n",
        "\n",
        "distribution = distribution.detach().numpy()"
      ],
      "metadata": {
        "id": "daON2zqBQld6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHpNYXtrQ82B",
        "outputId": "8692ef49-5d2e-44f8-c8e0-4080f1753c32"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiLayerTransformer(\n",
              "  (embedding): Embedding(1000, 2048)\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-9): 10 x DecoderBlock(\n",
              "      (self_attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=2048, out_features=2048, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (linear1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "      (linear2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "      (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Voocabulary Model"
      ],
      "metadata": {
        "id": "8_jh5SlNRbvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 100\n",
        "num_heads = 1\n",
        "ff_hidden_dim = 4*d_model\n",
        "dropout = 0.1\n",
        "num_layers = 4\n",
        "context_length = 5\n",
        "batch_size = 1\n",
        "\n",
        "vocab = [\n",
        "    \"natural\",\n",
        "    \"language\",\n",
        "    \"processing\",\n",
        "    \"machine\",\n",
        "    \"learning\",\n",
        "    \"algorithm\",\n",
        "    \"data\",\n",
        "    \"analysis\",\n",
        "    \"text\",\n",
        "    \"corpus\",\n",
        "    \"tokenization\",\n",
        "    \"sentiment\",\n",
        "    \"classification\",\n",
        "    \"entity\",\n",
        "    \"recognition\",\n",
        "    \"lemmatization\",\n",
        "    \"stemming\",\n",
        "    \"word2vec\",\n",
        "    \"embedding\",\n",
        "    \"part-of-speech\",\n",
        "    \"syntax\",\n",
        "    \"semantic\",\n",
        "    \"context\",\n",
        "    \"vector\",\n",
        "    \"feature\",\n",
        "    \"stopword\",\n",
        "    \"n-gram\",\n",
        "    \"bigram\",\n",
        "    \"trigram\",\n",
        "    \"preprocessing\",\n",
        "    \"post-processing\",\n",
        "    \"token\",\n",
        "    \"word\",\n",
        "    \"document\",\n",
        "    \"sentence\",\n",
        "    \"grammar\",\n",
        "    \"parsing\",\n",
        "    \"model\",\n",
        "    \"neural\",\n",
        "    \"network\",\n",
        "    \"RNN\",\n",
        "    \"LSTM\",\n",
        "    \"attention\",\n",
        "    \"transformer\",\n",
        "    \"BERT\",\n",
        "    \"GPT\",\n",
        "    \"evaluation\",\n",
        "    \"metrics\",\n",
        "    \"accuracy\",\n",
        "]\n",
        "\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "16n9qg-kRQ8K"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {word:id for id,word in enumerate(vocab)}\n",
        "\n",
        "id2word = {id:word for id, word in enumerate(vocab)}\n"
      ],
      "metadata": {
        "id": "NKDK-7fHSHNq"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiLayerTransformer(vocab_size, d_model, num_heads, ff_hidden_dim, dropout, num_layers)"
      ],
      "metadata": {
        "id": "S8M9xH7sSZVr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = ['evaluation', 'metrics', 'accuracy', 'analysis', 'processing'][:context_length]\n",
        "\n",
        "input_tensor = torch.tensor([[word2id[word] for word in sequence]])"
      ],
      "metadata": {
        "id": "G7g26ZwxSjFX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "generated_words = []\n",
        "for i in range(10):\n",
        "  output = model(input_tensor)\n",
        "  predicted_index = output.argmax(dim=-1)[0, -1] # Take the last word in sequence\n",
        "  predicted_word = id2word[predicted_index.item()]\n",
        "  print(predicted_word, end=' ')\n",
        "  generated_words.append(predicted_word)\n",
        "  input_tensor = torch.cat([input_tensor, predicted_index.unsqueeze(0).unsqueeze(0)], dim=-1)\n",
        "  time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xi7_0cMS3zV",
        "outputId": "930bb7c8-7cab-4280-8e19-e5f35d113504"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data preprocessing evaluation machine evaluation algorithm sentiment word2vec evaluation language "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a trained decoder and real-world vocabulary"
      ],
      "metadata": {
        "id": "BSnJfdPsuBPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_EMWy0yuYq_",
        "outputId": "6be4a8bc-971d-4146-af66-5c27fa23e7d0"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "BgpfTUccVqcj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3957fcPuqxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}